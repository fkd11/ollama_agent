# Weaviateã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ 
# import weaviate_control
import weaviate
from weaviate.classes.config import Configure, Property, DataType, Tokenization


WEAVIATE_SCHEMA = {
    "classes": [
        {
            "class": "Document",
            "description": "å­¦è¡“æ–‡çŒ®ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿",
            "vectorizer_config": [
                {
                    "name": "general_vector",
                    "vectorizer": {
                        "text2vec-ollama": {
                            "apiEndpoint": "http://host.docker.internal:11434",
                            "model": "dengcao/Qwen3-Embedding-0.6B:F16"
                        }
                    }
                }
            ],
            "generative_config": {
                "ollama": {
                    "apiEndpoint": "http://host.docker.internal:11434",
                    "model": "qwen3:0.6b"
                }
            },
            "properties": [
                # åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                {"name": "document_id", "dataType": ["text"], "description": "æ–‡æ›¸ã®ä¸€æ„è­˜åˆ¥å­", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "title", "dataType": ["text"], "description": "æ–‡çŒ®ã‚¿ã‚¤ãƒˆãƒ«", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "abstract", "dataType": ["text"], "description": "è¦ç´„", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "authors", "dataType": ["text[]"], "description": "è‘—è€…ãƒªã‚¹ãƒˆ", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "affiliations", "dataType": ["text[]"], "description": "æ‰€å±æ©Ÿé–¢", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "publication_date", "dataType": ["date"], "description": "ç™ºè¡Œæ—¥", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "journal_name", "dataType": ["text"], "description": "é›‘èªŒå", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "volume", "dataType": ["text"], "description": "å·»å·", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "issue", "dataType": ["text"], "description": "å·", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "pages", "dataType": ["text"], "description": "ãƒšãƒ¼ã‚¸ç¯„å›²", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "doi", "dataType": ["text"], "description": "DOI", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "arxiv_id", "dataType": ["text"], "description": "arXiv ID", "vectorizePropertyName": False, "skipVectorization": True},
                
                # å…¨æ–‡ãƒ‡ãƒ¼ã‚¿ç®¡ç†
                {"name": "has_full_text", "dataType": ["boolean"], "description": "å…¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "full_text_storage_type", "dataType": ["text"], "description": "å…¨æ–‡ä¿å­˜æ–¹å¼", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "full_text_url", "dataType": ["text"], "description": "å…¨æ–‡ã‚¢ã‚¯ã‚»ã‚¹URL", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "full_text_hash", "dataType": ["text"], "description": "å…¨æ–‡ã®ãƒãƒƒã‚·ãƒ¥å€¤", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "license_type", "dataType": ["text"], "description": "ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç¨®åˆ¥", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "access_permission", "dataType": ["text"], "description": "ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™", "vectorizePropertyName": False, "skipVectorization": True},
                
                # åˆ†é¡æƒ…å ±
                {"name": "keywords", "dataType": ["text[]"], "description": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "research_fields", "dataType": ["text[]"], "description": "ç ”ç©¶åˆ†é‡", "vectorizePropertyName": True, "skipVectorization": True},
                
                # ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†
                {"name": "created_at", "dataType": ["date"], "description": "ç™»éŒ²æ—¥æ™‚", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "updated_at", "dataType": ["date"], "description": "æ›´æ–°æ—¥æ™‚", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "source_url", "dataType": ["text"], "description": "å…ƒãƒ‡ãƒ¼ã‚¿ã®URL", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "file_path", "dataType": ["text"], "description": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹", "vectorizePropertyName": False, "skipVectorization": True},
                
                # è¨€èªãƒ»åœ°åŸŸæƒ…å ±
                {"name": "language", "dataType": ["text"], "description": "è¨€èª", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "country", "dataType": ["text"], "description": "ç™ºè¡Œå›½", "vectorizePropertyName": False, "skipVectorization": True},
                
                # çµ±è¨ˆæƒ…å ±
                {"name": "word_count", "dataType": ["int"], "description": "å˜èªæ•°", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "page_count", "dataType": ["int"], "description": "ãƒšãƒ¼ã‚¸æ•°", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "reference_count", "dataType": ["int"], "description": "å‚è€ƒæ–‡çŒ®æ•°", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "figure_count", "dataType": ["int"], "description": "å›³è¡¨æ•°", "vectorizePropertyName": False, "skipVectorization": True},
            ],
        },
        {
            "class": "Chunk",
            "description": "æ–‡çŒ®ã®åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯",
            "vectorizer": "text2vec-ollama",  # ãƒãƒ£ãƒ³ã‚¯ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ç”¨
            "properties": [
                # ãƒãƒ£ãƒ³ã‚¯åŸºæœ¬æƒ…å ±
                {"name": "chunk_id", "dataType": ["text"], "description": "ãƒãƒ£ãƒ³ã‚¯ã®ä¸€æ„è­˜åˆ¥å­", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "document_id", "dataType": ["text"], "description": "è¦ªæ–‡æ›¸ID", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "chunk_type", "dataType": ["text"], "description": "ãƒãƒ£ãƒ³ã‚¯ç¨®åˆ¥", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "content", "dataType": ["text"], "description": "ãƒãƒ£ãƒ³ã‚¯å†…å®¹", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "chunk_index", "dataType": ["int"], "description": "æ–‡æ›¸å†…ã§ã®é †åº", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "section_title", "dataType": ["text"], "description": "ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«", "vectorizePropertyName": True, "skipVectorization": True},
                
                # ä½ç½®æƒ…å ±
                {"name": "start_char", "dataType": ["int"], "description": "é–‹å§‹æ–‡å­—ä½ç½®", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "end_char", "dataType": ["int"], "description": "çµ‚äº†æ–‡å­—ä½ç½®", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "page_number", "dataType": ["int"], "description": "ãƒšãƒ¼ã‚¸ç•ªå·", "vectorizePropertyName": False, "skipVectorization": True},
                
                # å†…å®¹åˆ†æ
                {"name": "word_count", "dataType": ["int"], "description": "å˜èªæ•°", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "sentence_count", "dataType": ["int"], "description": "æ–‡æ•°", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "entities", "dataType": ["text[]"], "description": "æŠ½å‡ºã•ã‚ŒãŸå›ºæœ‰è¡¨ç¾", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "key_phrases", "dataType": ["text[]"], "description": "é‡è¦ãƒ•ãƒ¬ãƒ¼ã‚º", "vectorizePropertyName": True, "skipVectorization": True},
                
                # å“è³ªæŒ‡æ¨™
                {"name": "importance_score", "dataType": ["number"], "description": "é‡è¦åº¦ã‚¹ã‚³ã‚¢", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "readability_score", "dataType": ["number"], "description": "å¯èª­æ€§ã‚¹ã‚³ã‚¢", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "semantic_density", "dataType": ["number"], "description": "æ„å‘³å¯†åº¦", "vectorizePropertyName": False, "skipVectorization": True},
                
                # ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†
                {"name": "created_at", "dataType": ["date"], "description": "ä½œæˆæ—¥æ™‚", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "embedding_model", "dataType": ["text"], "description": "ä½¿ç”¨ã—ãŸåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "processing_version", "dataType": ["text"], "description": "å‡¦ç†ãƒãƒ¼ã‚¸ãƒ§ãƒ³", "vectorizePropertyName": False, "skipVectorization": True},
            ],
            "moduleConfig": {
                # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šï¼ˆOllamaï¼‰
                "text2vec-ollama": {
                    "apiEndpoint": "http://localhost:11434",
                    "model": "dengcao/Qwen3-Embedding-0.6B:F16"
                },
                # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–è¨­å®šï¼ˆOllamaï¼‰
                "generative-ollama": {
                    "apiEndpoint": "http://localhost:11434",
                    "model": "qwen3:0.6b"
                }
            }
        },
        {
            "class": "Author",
            "description": "è‘—è€…æƒ…å ±",
            "vectorizer": "text2vec-ollama",  # è‘—è€…åãƒ»ç ”ç©¶åˆ†é‡ã§ã®é¡ä¼¼æ¤œç´¢
            "properties": [
                {"name": "author_id", "dataType": ["text"], "description": "è‘—è€…ID", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "name", "dataType": ["text"], "description": "è‘—è€…å", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "normalized_name", "dataType": ["text"], "description": "æ­£è¦åŒ–ã•ã‚ŒãŸè‘—è€…å", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "affiliations", "dataType": ["text[]"], "description": "æ‰€å±æ©Ÿé–¢å±¥æ­´", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "orcid", "dataType": ["text"], "description": "ORCID ID", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "research_interests", "dataType": ["text[]"], "description": "ç ”ç©¶èˆˆå‘³", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "h_index", "dataType": ["number"], "description": "h-index", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "citation_count", "dataType": ["int"], "description": "ç·è¢«å¼•ç”¨æ•°", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "publication_count", "dataType": ["int"], "description": "å‡ºç‰ˆæ•°", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "email", "dataType": ["text"], "description": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "homepage", "dataType": ["text"], "description": "ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸URL", "vectorizePropertyName": False, "skipVectorization": True},
            ],
            "moduleConfig": {
                # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šï¼ˆOllamaï¼‰
                "text2vec-ollama": {
                    "apiEndpoint": "http://localhost:11434",
                    "model": "dengcao/Qwen3-Embedding-0.6B:F16"
                },
                # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–è¨­å®šï¼ˆOllamaï¼‰
                "generative-ollama": {
                    "apiEndpoint": "http://localhost:11434",
                    "model": "qwen3:0.6b"
                }
            }
        },
        {
            "class": "Concept",
            "description": "ç ”ç©¶æ¦‚å¿µãƒ»ãƒˆãƒ”ãƒƒã‚¯",
            "vectorizer": "text2vec-ollama",  # æ¦‚å¿µé–“ã®é¡ä¼¼æ€§æ¤œç´¢
            "properties": [
                {"name": "concept_id", "dataType": ["text"], "description": "æ¦‚å¿µID", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "name", "dataType": ["text"], "description": "æ¦‚å¿µå", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "description", "dataType": ["text"], "description": "æ¦‚å¿µã®èª¬æ˜", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "synonyms", "dataType": ["text[]"], "description": "åŒç¾©èª", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "category", "dataType": ["text"], "description": "ã‚«ãƒ†ã‚´ãƒª", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "frequency", "dataType": ["int"], "description": "å‡ºç¾é »åº¦", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "trend_score", "dataType": ["number"], "description": "ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ã‚³ã‚¢", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "related_concepts", "dataType": ["text[]"], "description": "é–¢é€£æ¦‚å¿µ", "vectorizePropertyName": True, "skipVectorization": True},
            ],
            "moduleConfig": {
                # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šï¼ˆOllamaï¼‰
                "text2vec-ollama": {
                    "apiEndpoint": "http://localhost:11434",
                    "model": "dengcao/Qwen3-Embedding-0.6B:F16"
                },
                # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–è¨­å®šï¼ˆOllamaï¼‰
                "generative-ollama": {
                    "apiEndpoint": "http://localhost:11434",
                    "model": "qwen3:0.6b"
                }
            }
        },
        {
            "class": "Citation",
            "description": "å¼•ç”¨é–¢ä¿‚",
            "vectorizer": "text2vec-ollama",  # å¼•ç”¨æ–‡è„ˆã®æ¤œç´¢
            "properties": [
                {"name": "citing_doc_id", "dataType": ["text"], "description": "å¼•ç”¨ã™ã‚‹æ–‡æ›¸ID", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "cited_doc_id", "dataType": ["text"], "description": "å¼•ç”¨ã•ã‚Œã‚‹æ–‡æ›¸ID", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "citation_context", "dataType": ["text"], "description": "å¼•ç”¨æ–‡è„ˆ", "vectorizePropertyName": True, "skipVectorization": True},
                {"name": "citation_type", "dataType": ["text"], "description": "å¼•ç”¨ã‚¿ã‚¤ãƒ—", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "confidence_score", "dataType": ["number"], "description": "ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢", "vectorizePropertyName": False, "skipVectorization": True},
                {"name": "created_at", "dataType": ["date"], "description": "ä½œæˆæ—¥æ™‚", "vectorizePropertyName": False, "skipVectorization": True},
            ],
            "moduleConfig": {
                # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šï¼ˆOllamaï¼‰
                "text2vec-ollama": {
                    "apiEndpoint": "http://localhost:11434",
                    "model": "dengcao/Qwen3-Embedding-0.6B:F16"
                },
                # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–è¨­å®šï¼ˆOllamaï¼‰
                "generative-ollama": {
                    "apiEndpoint": "http://localhost:11434",
                    "model": "qwen3:0.6b"
                }
            }
        }
    ]
}

client = weaviate.connect_to_local()
client.collections.delete_all()  # æ—¢å­˜å‰Šé™¤
for class_def in WEAVIATE_SCHEMA["classes"]:
            print(f"ã‚¯ãƒ©ã‚¹ '{class_def['class']}' ã‚’ä½œæˆä¸­...")
            client.collections.create_from_dict(class_def)

print("Weaviateã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆã—ã¾ã—ãŸã€‚")



# #














# # Weaviate + Ollama ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç”¨Docker Compose
# WEAVIATE_DOCKER_COMPOSE = """
# version: '3.4'
# services:
#   weaviate:
#     command:
#     - --host
#     - 0.0.0.0
#     - --port
#     - '8080'
#     - --scheme
#     - http
#     image: cr.weaviate.io/semitechnologies/weaviate:1.25.0
#     ports:
#     - "8080:8080"
#     - "50051:50051"
#     restart: on-failure:0
#     environment:
#       QUERY_DEFAULTS_LIMIT: 25
#       AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
#       PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
#       DEFAULT_VECTORIZER_MODULE: 'text2vec-ollama'
#       ENABLE_MODULES: 'text2vec-ollama,generative-ollama'
#       CLUSTER_HOSTNAME: 'node1'
#       # Ollamaè¨­å®š
#       TEXT2VEC_OLLAMA_API_ENDPOINT: 'http://host.docker.internal:11434'
#       GENERATIVE_OLLAMA_API_ENDPOINT: 'http://host.docker.internal:11434'
#     volumes:
#     - weaviate_data:/var/lib/weaviate
# volumes:
#   weaviate_data:
# """

# # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šã®èª¬æ˜
# """
# ğŸ¯ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šæ–¹é‡:

# Document ã‚¯ãƒ©ã‚¹:
# âœ… title, abstract, keywords, research_fields â†’ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
# âŒ IDs, dates, counts, system fields â†’ æ§‹é€ åŒ–æ¤œç´¢

# Chunk ã‚¯ãƒ©ã‚¹:
# âœ… content, section_title, entities, key_phrases â†’ å†…å®¹æ¤œç´¢
# âŒ IDs, positions, scores, system fields â†’ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œç´¢

# Author ã‚¯ãƒ©ã‚¹:
# âœ… name, affiliations, research_interests â†’ å°‚é–€æ€§æ¤œç´¢
# âŒ IDs, metrics, contact info â†’ æ§‹é€ åŒ–æ¤œç´¢

# Concept ã‚¯ãƒ©ã‚¹:
# âœ… name, description, synonyms, related_concepts â†’ æ¦‚å¿µæ¤œç´¢
# âŒ IDs, frequencies, categories â†’ çµ±è¨ˆçš„æ¤œç´¢

# Citation ã‚¯ãƒ©ã‚¹:
# âœ… citation_context â†’ å¼•ç”¨æ–‡è„ˆã®æ¤œç´¢
# âŒ IDs, types, scores â†’ é–¢ä¿‚æ€§ãƒ‡ãƒ¼ã‚¿æ¤œç´¢

# ğŸ’¡ åˆ©ç‚¹:
# 1. LlamaIndexã¨ã®ä½µç”¨å¯èƒ½ï¼ˆLlamaIndexãŒç‹¬è‡ªãƒ™ã‚¯ãƒˆãƒ«ç®¡ç†ã€WeaviateãŒDBã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ï¼‰
# 2. å‡¦ç†åŠ¹ç‡åŒ–ï¼ˆé‡è¦ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®ã¿ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
# 3. å¤šå±¤æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ« + æ§‹é€ åŒ–ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
# 4. ã‚³ã‚¹ãƒˆæœ€é©åŒ–ï¼ˆOllamaå‡¦ç†æ™‚é–“çŸ­ç¸®ï¼‰
# """

# # ä½¿ç”¨ä¾‹
# def setup_weaviate_with_ollama():
#     """
#     å®Œå…¨ãªWeaviate + Ollama + LlamaIndexç’°å¢ƒã®è¨­å®š
#     """
#     import weaviate
    
#     # Weaviateã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
#     client = weaviate.Client("http://localhost:8080")
    
#     # ã‚¹ã‚­ãƒ¼ãƒä½œæˆ
#     try:
#         client.schema.delete_all()  # æ—¢å­˜å‰Šé™¤
#         client.schema.create(WEAVIATE_SCHEMA)
#         print("âœ… All schemas created successfully with Ollama Qwen3!")
        
#         # ã‚¹ã‚­ãƒ¼ãƒç¢ºèª
#         schema = client.schema.get()
#         for cls in schema['classes']:
#             print(f"ğŸ“ Class: {cls['class']}")
#             vectorized_props = [p['name'] for p in cls['properties'] 
#                               if p.get('vectorizePropertyName', True)]
#             print(f"   ğŸ” Vectorized properties: {vectorized_props}")
            
#     except Exception as e:
#         print(f"âŒ Error: {e}")
    
#     return client

# # æ¤œç´¢ä¾‹
# def advanced_search_examples(client):
#     """
#     é«˜åº¦ãªæ¤œç´¢ä¾‹
#     """
    
#     # 1. Document: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ« + ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
#     results = (
#         client.query
#         .get("Document", ["title", "abstract", "publication_date"])
#         .with_near_text({"concepts": ["transformer neural network"]})
#         .with_where({
#             "path": ["publication_date"],
#             "operator": "GreaterThan", 
#             "valueDate": "2020-01-01T00:00:00Z"
#         })
#         .with_generate(single_prompt="ã“ã®è«–æ–‡ã®é©æ–°æ€§ã‚’æ—¥æœ¬èªã§èª¬æ˜ã—ã¦")
#         .with_limit(5)
#         .do()
#     )
    
#     # 2. Chunk: è©³ç´°å†…å®¹æ¤œç´¢
#     chunk_results = (
#         client.query
#         .get("Chunk", ["content", "section_title", "importance_score"])
#         .with_near_text({"concepts": ["attention mechanism implementation"]})
#         .with_where({
#             "path": ["importance_score"],
#             "operator": "GreaterThan",
#             "valueNumber": 0.7
#         })
#         .with_limit(10)
#         .do()
#     )
    
#     # 3. Author: ç ”ç©¶è€…æ¤œç´¢
#     author_results = (
#         client.query
#         .get("Author", ["name", "research_interests", "affiliations"])
#         .with_near_text({"concepts": ["deep learning computer vision"]})
#         .with_generate(single_prompt="ã“ã®ç ”ç©¶è€…ã®å°‚é–€åˆ†é‡ã‚’è¦ç´„ã—ã¦")
#         .do()
#     )
    
#     return results, chunk_results, author_results

# if __name__ == "__main__":
#     # Ollamaèµ·å‹•ç¢ºèª
#     print("ğŸš€ OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
#     print("   ollama serve")
#     print("   ollama pull qwen2.5:latest")
#     print()
    
#     # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Ÿè¡Œ
#     client = setup_weaviate_with_ollama()
    
#     # æ¤œç´¢ãƒ†ã‚¹ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
#     # results = advanced_search_examples(client)





# """
# æ–‡çŒ®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ
# LlamaIndex + Weaviate ã‚’ä½¿ç”¨ã—ãŸå­¦è¡“æ–‡çŒ®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
# """

# from typing import List, Dict, Optional, Any, Union
# from datetime import datetime
# from enum import Enum
# import uuid
# import logging
# from dataclasses import dataclass, field
# from pathlib import Path
# import hashlib
# import json

# # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)

# class ChunkType(Enum):
#     """ãƒãƒ£ãƒ³ã‚¯ã®ç¨®é¡"""
#     TITLE = "title"
#     ABSTRACT = "abstract"
#     INTRODUCTION = "introduction"
#     METHODOLOGY = "methodology"
#     RESULTS = "results"
#     DISCUSSION = "discussion"
#     CONCLUSION = "conclusion"
#     REFERENCE = "reference"
#     FIGURE_CAPTION = "figure_caption"
#     TABLE_CAPTION = "table_caption"
#     FULL_TEXT = "full_text"

# class DocumentType(Enum):
#     """æ–‡æ›¸ã®ç¨®é¡"""
#     JOURNAL_ARTICLE = "journal_article"
#     CONFERENCE_PAPER = "conference_paper"
#     BOOK_CHAPTER = "book_chapter"
#     THESIS = "thesis"
#     PREPRINT = "preprint"
#     PATENT = "patent"
#     REPORT = "report"

# class ProcessingStatus(Enum):
#     """å‡¦ç†çŠ¶æ³"""
#     PENDING = "pending"
#     PROCESSING = "processing"
#     COMPLETED = "completed"
#     FAILED = "failed"
#     NEEDS_REVIEW = "needs_review"

# class StorageType(Enum):
#     """å…¨æ–‡ä¿å­˜æ–¹å¼"""
#     EMBEDDED = "embedded"
#     EXTERNAL = "external"
#     REFERENCE = "reference"

# # Weaviate ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆ
# WEAVIATE_SCHEMA = {
#     "classes": [
#         {
#             "class": "Document",
#             "description": "å­¦è¡“æ–‡çŒ®ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿",
#             "vectorizer": "none",  # LlamaIndexã§ç®¡ç†
#             "properties": [
#                 # åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
#                 {"name": "document_id", "dataType": ["text"], "description": "æ–‡æ›¸ã®ä¸€æ„è­˜åˆ¥å­"},
#                 {"name": "title", "dataType": ["text"], "description": "æ–‡çŒ®ã‚¿ã‚¤ãƒˆãƒ«"},
#                 {"name": "abstract", "dataType": ["text"], "description": "è¦ç´„"},
#                 {"name": "authors", "dataType": ["text[]"], "description": "è‘—è€…ãƒªã‚¹ãƒˆ"},
#                 {"name": "affiliations", "dataType": ["text[]"], "description": "æ‰€å±æ©Ÿé–¢"},
#                 {"name": "publication_date", "dataType": ["date"], "description": "ç™ºè¡Œæ—¥"},
#                 {"name": "journal_name", "dataType": ["text"], "description": "é›‘èªŒå"},
#                 {"name": "volume", "dataType": ["text"], "description": "å·»å·"},
#                 {"name": "issue", "dataType": ["text"], "description": "å·"},
#                 {"name": "pages", "dataType": ["text"], "description": "ãƒšãƒ¼ã‚¸ç¯„å›²"},
#                 {"name": "doi", "dataType": ["text"], "description": "DOI"},
#                 # {"name": "pmid", "dataType": ["text"], "description": "PubMed ID"},
#                 {"name": "arxiv_id", "dataType": ["text"], "description": "arXiv ID"},
                
#                 # å…¨æ–‡ãƒ‡ãƒ¼ã‚¿ç®¡ç†
#                 {"name": "has_full_text", "dataType": ["boolean"], "description": "å…¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡"},
#                 {"name": "full_text_storage_type", "dataType": ["text"], "description": "å…¨æ–‡ä¿å­˜æ–¹å¼"},
#                 {"name": "full_text_url", "dataType": ["text"], "description": "å…¨æ–‡ã‚¢ã‚¯ã‚»ã‚¹URL"},
#                 {"name": "full_text_hash", "dataType": ["text"], "description": "å…¨æ–‡ã®ãƒãƒƒã‚·ãƒ¥å€¤"},
#                 {"name": "license_type", "dataType": ["text"], "description": "ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç¨®åˆ¥"},
#                 {"name": "access_permission", "dataType": ["text"], "description": "ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™"},
                
#                 # åˆ†é¡æƒ…å ±
#                 # {"name": "document_type", "dataType": ["text"], "description": "æ–‡æ›¸ç¨®åˆ¥"},
#                 # {"name": "subject_categories", "dataType": ["text[]"], "description": "ä¸»é¡Œåˆ†é¡"},
#                 {"name": "keywords", "dataType": ["text[]"], "description": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"},
#                 {"name": "research_fields", "dataType": ["text[]"], "description": "ç ”ç©¶åˆ†é‡"},
                
#                 # # å“è³ªãƒ»é‡è¦åº¦æŒ‡æ¨™
#                 # {"name": "citation_count", "dataType": ["int"], "description": "è¢«å¼•ç”¨æ•°"},
#                 # {"name": "impact_factor", "dataType": ["number"], "description": "ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼"},
#                 # {"name": "h_index", "dataType": ["number"], "description": "è‘—è€…ã®h-index"},
#                 # {"name": "quality_score", "dataType": ["number"], "description": "å“è³ªã‚¹ã‚³ã‚¢"},
                
#                 # ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†
#                 {"name": "created_at", "dataType": ["date"], "description": "ç™»éŒ²æ—¥æ™‚"},
#                 {"name": "updated_at", "dataType": ["date"], "description": "æ›´æ–°æ—¥æ™‚"},
#                 {"name": "source_url", "dataType": ["text"], "description": "å…ƒãƒ‡ãƒ¼ã‚¿ã®URL"},
#                 {"name": "file_path", "dataType": ["text"], "description": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"},
#                 # {"name": "processing_status", "dataType": ["text"], "description": "å‡¦ç†çŠ¶æ³"},
                
#                 # è¨€èªãƒ»åœ°åŸŸæƒ…å ±
#                 {"name": "language", "dataType": ["text"], "description": "è¨€èª"},
#                 {"name": "country", "dataType": ["text"], "description": "ç™ºè¡Œå›½"},
                
#                 # çµ±è¨ˆæƒ…å ±
#                 {"name": "word_count", "dataType": ["int"], "description": "å˜èªæ•°"},
#                 {"name": "page_count", "dataType": ["int"], "description": "ãƒšãƒ¼ã‚¸æ•°"},
#                 {"name": "reference_count", "dataType": ["int"], "description": "å‚è€ƒæ–‡çŒ®æ•°"},
#                 {"name": "figure_count", "dataType": ["int"], "description": "å›³è¡¨æ•°"},
#             ],
#             "moduleConfig": {
#                 "generative-openai": {
#                     "model": "gpt-4"
#                 }
#             }
#         },
#         {
#             "class": "Chunk",
#             "description": "æ–‡çŒ®ã®åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯",
#             "vectorizer": "none",  # LlamaIndexã§ç®¡ç†
#             "properties": [
#                 # ãƒãƒ£ãƒ³ã‚¯åŸºæœ¬æƒ…å ±
#                 {"name": "chunk_id", "dataType": ["text"], "description": "ãƒãƒ£ãƒ³ã‚¯ã®ä¸€æ„è­˜åˆ¥å­"},
#                 {"name": "document_id", "dataType": ["text"], "description": "è¦ªæ–‡æ›¸ID"},
#                 {"name": "chunk_type", "dataType": ["text"], "description": "ãƒãƒ£ãƒ³ã‚¯ç¨®åˆ¥"},
#                 {"name": "content", "dataType": ["text"], "description": "ãƒãƒ£ãƒ³ã‚¯å†…å®¹"},
#                 {"name": "chunk_index", "dataType": ["int"], "description": "æ–‡æ›¸å†…ã§ã®é †åº"},
#                 {"name": "section_title", "dataType": ["text"], "description": "ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«"},
                
#                 # ä½ç½®æƒ…å ±
#                 {"name": "start_char", "dataType": ["int"], "description": "é–‹å§‹æ–‡å­—ä½ç½®"},
#                 {"name": "end_char", "dataType": ["int"], "description": "çµ‚äº†æ–‡å­—ä½ç½®"},
#                 {"name": "page_number", "dataType": ["int"], "description": "ãƒšãƒ¼ã‚¸ç•ªå·"},
                
#                 # å†…å®¹åˆ†æ
#                 {"name": "word_count", "dataType": ["int"], "description": "å˜èªæ•°"},
#                 {"name": "sentence_count", "dataType": ["int"], "description": "æ–‡æ•°"},
#                 {"name": "entities", "dataType": ["text[]"], "description": "æŠ½å‡ºã•ã‚ŒãŸå›ºæœ‰è¡¨ç¾"},
#                 {"name": "key_phrases", "dataType": ["text[]"], "description": "é‡è¦ãƒ•ãƒ¬ãƒ¼ã‚º"},
                
#                 # å“è³ªæŒ‡æ¨™
#                 {"name": "importance_score", "dataType": ["number"], "description": "é‡è¦åº¦ã‚¹ã‚³ã‚¢"},
#                 {"name": "readability_score", "dataType": ["number"], "description": "å¯èª­æ€§ã‚¹ã‚³ã‚¢"},
#                 {"name": "semantic_density", "dataType": ["number"], "description": "æ„å‘³å¯†åº¦"},
                
#                 # ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†
#                 {"name": "created_at", "dataType": ["date"], "description": "ä½œæˆæ—¥æ™‚"},
#                 {"name": "embedding_model", "dataType": ["text"], "description": "ä½¿ç”¨ã—ãŸåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«"},
#                 {"name": "processing_version", "dataType": ["text"], "description": "å‡¦ç†ãƒãƒ¼ã‚¸ãƒ§ãƒ³"},
#             ]
#         },
#         {
#             "class": "Author",
#             "description": "è‘—è€…æƒ…å ±",
#             "vectorizer": "none",
#             "properties": [
#                 {"name": "author_id", "dataType": ["text"], "description": "è‘—è€…ID"},
#                 {"name": "name", "dataType": ["text"], "description": "è‘—è€…å"},
#                 {"name": "normalized_name", "dataType": ["text"], "description": "æ­£è¦åŒ–ã•ã‚ŒãŸè‘—è€…å"},
#                 {"name": "affiliations", "dataType": ["text[]"], "description": "æ‰€å±æ©Ÿé–¢å±¥æ­´"},
#                 {"name": "orcid", "dataType": ["text"], "description": "ORCID ID"},
#                 {"name": "research_interests", "dataType": ["text[]"], "description": "ç ”ç©¶èˆˆå‘³"},
#                 {"name": "h_index", "dataType": ["number"], "description": "h-index"},
#                 {"name": "citation_count", "dataType": ["int"], "description": "ç·è¢«å¼•ç”¨æ•°"},
#                 {"name": "publication_count", "dataType": ["int"], "description": "å‡ºç‰ˆæ•°"},
#                 {"name": "email", "dataType": ["text"], "description": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"},
#                 {"name": "homepage", "dataType": ["text"], "description": "ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸URL"},
#             ]
#         },
#         {
#             "class": "Concept",
#             "description": "ç ”ç©¶æ¦‚å¿µãƒ»ãƒˆãƒ”ãƒƒã‚¯",
#             "vectorizer": "none",
#             "properties": [
#                 {"name": "concept_id", "dataType": ["text"], "description": "æ¦‚å¿µID"},
#                 {"name": "name", "dataType": ["text"], "description": "æ¦‚å¿µå"},
#                 {"name": "description", "dataType": ["text"], "description": "æ¦‚å¿µã®èª¬æ˜"},
#                 {"name": "synonyms", "dataType": ["text[]"], "description": "åŒç¾©èª"},
#                 {"name": "category", "dataType": ["text"], "description": "ã‚«ãƒ†ã‚´ãƒª"},
#                 {"name": "frequency", "dataType": ["int"], "description": "å‡ºç¾é »åº¦"},
#                 {"name": "trend_score", "dataType": ["number"], "description": "ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ã‚³ã‚¢"},
#                 {"name": "related_concepts", "dataType": ["text[]"], "description": "é–¢é€£æ¦‚å¿µ"},
#             ]
#         },
#         {
#             "class": "Citation",
#             "description": "å¼•ç”¨é–¢ä¿‚",
#             "vectorizer": "none",
#             "properties": [
#                 {"name": "citing_doc_id", "dataType": ["text"], "description": "å¼•ç”¨ã™ã‚‹æ–‡æ›¸ID"},
#                 {"name": "cited_doc_id", "dataType": ["text"], "description": "å¼•ç”¨ã•ã‚Œã‚‹æ–‡æ›¸ID"},
#                 {"name": "citation_context", "dataType": ["text"], "description": "å¼•ç”¨æ–‡è„ˆ"},
#                 {"name": "citation_type", "dataType": ["text"], "description": "å¼•ç”¨ã‚¿ã‚¤ãƒ—"},
#                 {"name": "confidence_score", "dataType": ["number"], "description": "ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢"},
#                 {"name": "created_at", "dataType": ["date"], "description": "ä½œæˆæ—¥æ™‚"},
#             ]
#         }
#     ]
# }

# @dataclass
# class LiteratureDocument:
#     """LlamaIndexã§ä½¿ç”¨ã™ã‚‹æ–‡çŒ®æ–‡æ›¸ã‚¯ãƒ©ã‚¹"""
#     document_id: str = field(default_factory=lambda: str(uuid.uuid4()))
#     title: str = ""
#     abstract: str = ""
#     full_text: str = ""
#     authors: List[str] = field(default_factory=list)
#     publication_date: Optional[datetime] = None
#     doi: Optional[str] = None
#     document_type: DocumentType = DocumentType.JOURNAL_ARTICLE
#     metadata: Dict[str, Any] = field(default_factory=dict)
#     chunks: List[Dict] = field(default_factory=list)
    
#     def __post_init__(self):
#         """åˆæœŸåŒ–å¾Œã®å‡¦ç†"""
#         if not self.metadata.get('created_at'):
#             self.metadata['created_at'] = datetime.now().isoformat()
    
#     def to_llamaindex_document(self):
#         """LlamaIndexã®Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›"""
#         try:
#             from llama_index.core import Document
            
#             # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
#             metadata = {
#                 "document_id": self.document_id,
#                 "title": self.title,
#                 "abstract": self.abstract,
#                 "authors": self.authors,
#                 "publication_date": self.publication_date.isoformat() if self.publication_date else None,
#                 "doi": self.doi,
#                 "document_type": self.document_type.value,
#                 **self.metadata
#             }
            
#             # å…¨æ–‡ãŒç©ºã®å ´åˆã¯æŠ„éŒ²ã‚’ä½¿ç”¨
#             text_content = self.full_text or self.abstract or self.title
            
#             return Document(
#                 text=text_content,
#                 doc_id=self.document_id,
#                 metadata=metadata
#             )
#         except ImportError:
#             logger.error("LlamaIndex not installed. Please install llama-index.")
#             raise
    
#     def generate_hash(self) -> str:
#         """æ–‡æ›¸ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ç”Ÿæˆ"""
#         content = f"{self.title}{self.abstract}{self.full_text}"
#         return hashlib.sha256(content.encode()).hexdigest()
    
#     def validate(self) -> bool:
#         """æ–‡æ›¸ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
#         if not self.title:
#             logger.warning(f"Document {self.document_id} has no title")
#             return False
        
#         if not self.abstract and not self.full_text:
#             logger.warning(f"Document {self.document_id} has no content")
#             return False
        
#         return True

# # è¨­å®šã‚¯ãƒ©ã‚¹
# @dataclass
# class IndexConfig:
#     """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®š"""
#     embedding_model: str = "text-embedding-3-large"
#     chunk_size: int = 512
#     chunk_overlap: int = 50
#     similarity_top_k: int = 10
#     similarity_threshold: float = 0.7
#     rerank_top_n: int = 5
#     batch_size: int = 100
    
#     def to_dict(self) -> Dict[str, Any]:
#         """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
#         return {
#             "embedding_model": self.embedding_model,
#             "chunk_size": self.chunk_size,
#             "chunk_overlap": self.chunk_overlap,
#             "similarity_top_k": self.similarity_top_k,
#             "similarity_threshold": self.similarity_threshold,
#             "rerank_top_n": self.rerank_top_n,
#             "batch_size": self.batch_size
#         }

# @dataclass
# class SearchConfig:
#     """æ¤œç´¢è¨­å®š"""
#     hybrid_search: bool = True
#     filters: Dict[str, Any] = field(default_factory=dict)
#     boost_fields: Dict[str, float] = field(default_factory=dict)
    
#     def __post_init__(self):
#         """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š"""
#         if not self.filters:
#             self.filters = {
#                 "publication_date": {"gte": "2020-01-01"},
#                 "document_type": ["journal_article", "conference_paper"],
#                 "citation_count": {"gte": 10}
#             }
        
#         if not self.boost_fields:
#             self.boost_fields = {
#                 "title": 2.0,
#                 "abstract": 1.5,
#                 "keywords": 1.2
#             }

# # å…¨æ–‡ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹
# class FullTextManager:
#     """å…¨æ–‡ãƒ‡ãƒ¼ã‚¿ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç®¡ç†"""
    
#     def __init__(self, storage_config: Dict[str, Any]):
#         self.storage_config = storage_config
#         self.cache = {}  # ã‚·ãƒ³ãƒ—ãƒ«ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
#     def get_full_text(self, document_id: str) -> Optional[str]:
#         """æ–‡æ›¸IDã‹ã‚‰å…¨æ–‡ã‚’å–å¾—"""
#         try:
#             # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
#             if document_id in self.cache:
#                 return self.cache[document_id]
                
#             doc_meta = self.get_document_metadata(document_id)
#             if not doc_meta:
#                 return None
                
#             storage_type = doc_meta.get("full_text_storage_type")
            
#             if storage_type == StorageType.EMBEDDED.value:
#                 text = self._get_embedded_text(document_id)
#             elif storage_type == StorageType.EXTERNAL.value:
#                 text = self._get_external_text(doc_meta.get("full_text_url"))
#             elif storage_type == StorageType.REFERENCE.value:
#                 text = self._get_reference_text(doc_meta.get("full_text_url"))
#             else:
#                 logger.warning(f"Unknown storage type: {storage_type}")
#                 return None
            
#             # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
#             if text:
#                 self.cache[document_id] = text
                
#             return text
            
#         except Exception as e:
#             logger.error(f"Error getting full text for document {document_id}: {e}")
#             return None
    
#     def get_document_metadata(self, document_id: str) -> Optional[Dict[str, Any]]:
#         """æ–‡æ›¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå®Ÿè£…å¿…è¦ï¼‰"""
#         # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Weaviateã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
#         pass
    
#     def get_document_chunks(self, document_id: str) -> List[Dict]:
#         """æ–‡æ›¸ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆå®Ÿè£…å¿…è¦ï¼‰"""
#         # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Weaviateã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
#         pass
    
#     def _get_embedded_text(self, document_id: str) -> Optional[str]:
#         """åŸ‹ã‚è¾¼ã¿ä¿å­˜ã•ã‚ŒãŸå…¨æ–‡ã‚’å–å¾—"""
#         try:
#             chunks = self.get_document_chunks(document_id)
#             if not chunks:
#                 return None
                
#             # ãƒãƒ£ãƒ³ã‚¯ã‚’é †åºã§ã‚½ãƒ¼ãƒˆã—ã¦çµåˆ
#             sorted_chunks = sorted(chunks, key=lambda x: x.get("chunk_index", 0))
#             return "".join([chunk.get("content", "") for chunk in sorted_chunks])
            
#         except Exception as e:
#             logger.error(f"Error getting embedded text: {e}")
#             return None
    
#     def _get_external_text(self, url: str) -> Optional[str]:
#         """å¤–éƒ¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰å…¨æ–‡ã‚’å–å¾—"""
#         try:
#             # S3, GCSç­‰ã‹ã‚‰å–å¾—ã®å®Ÿè£…
#             # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€boto3ã‚„google-cloud-storageã‚’ä½¿ç”¨
#             logger.info(f"Fetching text from external storage: {url}")
#             return None  # å®Ÿè£…å¿…è¦
#         except Exception as e:
#             logger.error(f"Error getting external text from {url}: {e}")
#             return None
    
#     def _get_reference_text(self, url: str) -> Optional[str]:
#         """å‚ç…§URLã‹ã‚‰å…¨æ–‡ã‚’å–å¾—"""
#         try:
#             # å…ƒã‚µã‚¤ãƒˆã‚„APIã‹ã‚‰å–å¾—ã®å®Ÿè£…
#             # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€requestsç­‰ã‚’ä½¿ç”¨
#             logger.info(f"Fetching text from reference URL: {url}")
#             return None  # å®Ÿè£…å¿…è¦
#         except Exception as e:
#             logger.error(f"Error getting reference text from {url}: {e}")
#             return None

# # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹
# class LiteratureVectorDB:
#     """æ–‡çŒ®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
#     def __init__(self, weaviate_client, config: IndexConfig):
#         self.client = weaviate_client
#         self.config = config
#         self.full_text_manager = FullTextManager({})
        
#     def create_schema(self):
#         """Weaviateã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆ"""
#         try:
#             # æ—¢å­˜ã®ã‚¹ã‚­ãƒ¼ãƒã‚’å‰Šé™¤ï¼ˆé–‹ç™ºç’°å¢ƒã®ã¿ï¼‰
#             existing_classes = self.client.schema.get()["classes"]
#             for cls in existing_classes:
#                 if cls["class"] in [c["class"] for c in WEAVIATE_SCHEMA["classes"]]:
#                     self.client.schema.delete_class(cls["class"])
            
#             # æ–°ã—ã„ã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆ
#             for class_config in WEAVIATE_SCHEMA["classes"]:
#                 self.client.schema.create_class(class_config)
                
#             logger.info("Schema created successfully")
            
#         except Exception as e:
#             logger.error(f"Error creating schema: {e}")
#             raise
    
#     def create_index(self, documents: List[LiteratureDocument]):
#         """æ–‡çŒ®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ"""
#         try:
#             from llama_index.core import VectorStoreIndex, StorageContext
#             from llama_index.vector_stores.weaviate import WeaviateVectorStore
            
#             # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢è¨­å®š
#             vector_store = WeaviateVectorStore(
#                 weaviate_client=self.client,
#                 index_name="Document",
#                 text_key="content"
#             )
            
#             # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
#             storage_context = StorageContext.from_defaults(vector_store=vector_store)
            
#             # æ–‡æ›¸ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
#             valid_documents = [doc for doc in documents if doc.validate()]
#             logger.info(f"Processing {len(valid_documents)} valid documents")
            
#             # LlamaIndexãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¤‰æ›
#             llama_docs = [doc.to_llamaindex_document() for doc in valid_documents]
            
#             # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
#             index = VectorStoreIndex.from_documents(
#                 documents=llama_docs,
#                 storage_context=storage_context,
#                 embed_model=self.config.embedding_model,
#                 show_progress=True
#             )
            
#             logger.info("Index created successfully")
#             return index
            
#         except Exception as e:
#             logger.error(f"Error creating index: {e}")
#             raise
    
#     def search_literature(self, index, query: str, search_config: SearchConfig):
#         """æ–‡çŒ®æ¤œç´¢"""
#         try:
#             retriever = index.as_retriever(
#                 similarity_top_k=self.config.similarity_top_k,
#                 filters=search_config.filters
#             )
            
#             results = retriever.retrieve(query)
            
#             # çµæœã®å¾Œå‡¦ç†
#             processed_results = []
#             for result in results:
#                 processed_results.append({
#                     "document_id": result.metadata.get("document_id"),
#                     "title": result.metadata.get("title"),
#                     "score": result.score,
#                     "content": result.text,
#                     "metadata": result.metadata
#                 })
            
#             return processed_results
            
#         except Exception as e:
#             logger.error(f"Error searching literature: {e}")
#             return []

# # ä½¿ç”¨ä¾‹
# def create_literature_system():
#     """æ–‡çŒ®ã‚·ã‚¹ãƒ†ãƒ ã®ä½œæˆä¾‹"""
#     try:
#         import weaviate
        
#         # Weaviateã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
#         client = weaviate.Client(
#             url="http://localhost:8080",
#             additional_headers={"X-OpenAI-Api-Key": "your-api-key"}
#         )
        
#         # è¨­å®š
#         config = IndexConfig(
#             embedding_model="text-embedding-3-large",
#             chunk_size=512,
#             chunk_overlap=50
#         )
        
#         # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
#         system = LiteratureVectorDB(client, config)
#         system.create_schema()
        
#         # ã‚µãƒ³ãƒ—ãƒ«æ–‡çŒ®ä½œæˆ
#         sample_doc = LiteratureDocument(
#             title="Sample Research Paper",
#             abstract="This is a sample abstract for demonstration purposes.",
#             authors=["John Doe", "Jane Smith"],
#             publication_date=datetime.now(),
#             doi="10.1000/sample.doi"
#         )
        
#         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
#         index = system.create_index([sample_doc])
        
#         # æ¤œç´¢è¨­å®š
#         search_config = SearchConfig(
#             hybrid_search=True,
#             filters={"document_type": ["journal_article"]}
#         )
        
#         # æ¤œç´¢å®Ÿè¡Œ
#         results = system.search_literature(index, "sample query", search_config)
        
#         return system, index, results
        
#     except ImportError:
#         logger.error("Required libraries not installed. Please install weaviate-client and llama-index.")
#         return None, None, None

# # æ¨å¥¨è¨­å®š
# RECOMMENDED_STORAGE_CONFIG = {
#     "open_access": StorageType.EMBEDDED.value,
#     "subscription": StorageType.REFERENCE.value,
#     "internal": StorageType.EMBEDDED.value,
#     "large_corpus": StorageType.EXTERNAL.value,
    
#     "chunk_only_mode": True,
#     "abstract_always_embedded": True,
#     "compression": "gzip",
#     "encryption": True,
#     "max_cache_size": 1000,
#     "cache_ttl": 3600,  # 1æ™‚é–“
# }

# # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ»åŒæœŸã®è¨­å®š
# SYNC_CONFIG = {
#     "incremental_update": True,
#     "batch_size": 1000,
#     "parallel_processing": True,
#     "backup_interval": "weekly",
#     "index_rebuild_interval": "monthly",
#     "max_retries": 3,
#     "retry_delay": 5,  # ç§’
# }

# if __name__ == "__main__":
#     # ã‚·ã‚¹ãƒ†ãƒ ã®ä½œæˆã¨å®Ÿè¡Œ
#     system, index, results = create_literature_system()
#     if system:
#         logger.info("Literature system created successfully")
#         if results:
#             logger.info(f"Found {len(results)} search results")
#     else:
#         logger.error("Failed to create literature system")